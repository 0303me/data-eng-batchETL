version: "3.9"

services:
  postgres:
    image: postgres:15
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    ports: ["5432:5432"]
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 5s
      timeout: 5s
      retries: 10

  minio:
    image: minio/minio:latest
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    ports: ["9000:9000", "9001:9001"]
    volumes:
      - minio-data:/data
    healthcheck:
      test: ["CMD-SHELL", "curl -fsS http://127.0.0.1:9000/minio/health/live || exit 1"]
      interval: 5s
      timeout: 3s
      retries: 12

  create-bucket:
    image: minio/mc:latest
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: >-
      /bin/sh -c "
      until mc alias set local http://minio:9000 ${MINIO_ROOT_USER} ${MINIO_ROOT_PASSWORD} 2>/dev/null;
      do echo 'waiting for minio' && sleep 2; done;
      mc mb -p local/${MINIO_BUCKET} || true;
      mc anonymous set download local/${MINIO_BUCKET} || true;
      echo 'Bucket ready'"

  # ---- AIRFLOW ----
  airflow-init:
    image: apache/airflow:2.9.3
    environment:
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      AIRFLOW__CORE__LOAD_EXAMPLES: ${AIRFLOW__CORE__LOAD_EXAMPLES:-False}
      PYTHONPATH: /opt/airflow
      _PIP_ADDITIONAL_REQUIREMENTS: >
        -c https://raw.githubusercontent.com/apache/airflow/constraints-2.9.3/constraints-3.12.txt
        boto3 structlog prometheus-client pyarrow pandas psycopg2-binary
    user: "${AIRFLOW_UID:-50000}:${AIRFLOW_GID:-0}"
    depends_on:
      postgres:
        condition: service_healthy
    volumes:
      - ./infra/airflow/dags:/opt/airflow/dags
      - ./infra/airflow/plugins:/opt/airflow/plugins
      - ./common:/opt/airflow/common
      - ./infra/airflow/logs:/opt/airflow/logs
    entrypoint: >
      /bin/bash -eo pipefail -c
      "airflow db init &&
      airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com &&
      echo 'Airflow DB initialized and admin user created.'"
    restart: "no"

  airflow-webserver:
    image: apache/airflow:2.9.3
    environment:
      AIRFLOW__CORE__LOAD_EXAMPLES: ${AIRFLOW__CORE__LOAD_EXAMPLES:-False}
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      PYTHONPATH: /opt/airflow
      _PIP_ADDITIONAL_REQUIREMENTS: >
        -c https://raw.githubusercontent.com/apache/airflow/constraints-2.9.3/constraints-3.12.txt
        boto3 structlog prometheus-client pyarrow pandas psycopg2-binary
    user: "${AIRFLOW_UID:-50000}:${AIRFLOW_GID:-0}"
    depends_on:
      postgres:
        condition: service_healthy
      airflow-init:
        condition: service_completed_successfully
    volumes:
      - ./infra/airflow/dags:/opt/airflow/dags
      - ./infra/airflow/plugins:/opt/airflow/plugins
      - ./common:/opt/airflow/common
      - ./infra/airflow/logs:/opt/airflow/logs
    ports: ["8080:8080"]
    command: ["airflow", "webserver"]

  airflow-scheduler:
    image: apache/airflow:2.9.3
    environment:
      AIRFLOW__CORE__LOAD_EXAMPLES: ${AIRFLOW__CORE__LOAD_EXAMPLES:-False}
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      PYTHONPATH: /opt/airflow
      _PIP_ADDITIONAL_REQUIREMENTS: >
        -c https://raw.githubusercontent.com/apache/airflow/constraints-2.9.3/constraints-3.12.txt
        boto3 structlog prometheus-client pyarrow pandas psycopg2-binary
    user: "${AIRFLOW_UID:-50000}:${AIRFLOW_GID:-0}"
    depends_on:
      postgres:
        condition: service_healthy
      airflow-init:
        condition: service_completed_successfully
    volumes:
      - ./infra/airflow/dags:/opt/airflow/dags
      - ./infra/airflow/plugins:/opt/airflow/plugins
      - ./common:/opt/airflow/common
      - ./infra/airflow/logs:/opt/airflow/logs
    command: ["airflow", "scheduler"]

  metabase:
    image: metabase/metabase:v0.49.15
    ports: ["3000:3000"]

volumes:
  minio-data:
